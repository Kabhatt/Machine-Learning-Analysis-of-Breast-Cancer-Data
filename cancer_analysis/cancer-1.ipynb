{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative Analysis of Breast Cancer Studies Replicated. \n",
    "\n",
    "## About this study:\n",
    "This project was inspired by a research article  by Muhammet Fatih AK, [A Comparative Analysis of Breast Cancer Detection and Diagnosis Using Data Visualization and Machine Learning Applications](https://www.mdpi.com/2227-9032/8/2/111). \n",
    "\n",
    "## Introduction:\n",
    "   It's a very well-known fact that cancer is the most complicated of all the disease types. Cancer and it's treatment, as seen from modern day research, is indiviual dependent. Meaning that camcer is as a disease behaves in various ways, and how the immunue system responds to treatment is different. This is why there is a new focus on personalized cancer therapies in research and medicine. A great tool for the developmet of these therapies is data science and ML techniques, but these tools are also great at predicting early cancer diagnosis. The research paper referenced in this artcle is an attempt to do a comparative analysis of breast cancer using dataset from different studies to compare their own Machine Learning Algorithm's outcomes using a data set from University of Wisconsin. \n",
    "   \n",
    "   \n",
    "## Dataset Used: \n",
    "   Since I couldn't find the original dataset used in this article. I went on to Google to find the original dataset by Dr. Wolberg. The dataset is describes the characteristics of the cancerous cell and the patient ids and diagnosis. The data can be foudn at [UC Irvin Machine Learning Repository](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic). We can also use use the university's remote server to downlaod the data: \n",
    " [university's remote server](ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/)\n",
    " and the command line: \n",
    " ftp ftp.cs.wisc.edu\n",
    " \n",
    "## Steps To use the FTP reote server: \n",
    "# Download: \n",
    "\n",
    "    1. Install FTP Client, if you are accessing the database outside the university. Some examples are: \n",
    "    + 1a. FileZilla\n",
    "    + 1b. Cyberduck\n",
    "    + 1c. Command-Line FTP\n",
    "    2. Launch the FTP server on your laptop. \n",
    "  \n",
    "# Steps: \n",
    "    1. Open the terminal on your desktop\n",
    "    2. tye this on the command line: \n",
    "      ```ftp ftp.cs.wisc.edu```\n",
    "    3. Enter the password and the username if needed \n",
    "    4. Once you are inside the server enter cd to change the directory, and use this code: \n",
    "    ```cd math-prog/cpo-dataset/machine-learn/WDBC/```\n",
    "    5. Once inside use the commands ls or dir. \n",
    "      a. ls- is a linux command that list the files and directories in the current directory, associated with Unix-like systems \n",
    "      b. dir - is a linux command that lists the files and directories as well but its often associated with  Windows and MS-DOS                     environments r\n",
    "    6. Now if we wanted to download the data we would use the get command like: \n",
    "    ```get example.txt```\n",
    "    7. Finally if we want to quit the bash, we would use the command quit. \n",
    "  \n",
    "  For the ease of this projet I will just download the database on my laptop.\n",
    "  \n",
    "## Downloading the Data: \n",
    "\n",
    "    1. First I downladed the dataset from the internet.\n",
    "    2. Now we code so that we can read and present the data. \n",
    "    3. we imported this data on python. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will need to install the packages for the library to access the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our requirement was already satisfied. Next we will need to import that data. In order to import the data on our machine, we needed to import ssl, which is a secured socket layer. We have to disable this so we we can extract the data. The command below allows us to trust the SSL certficate to do so.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "# Disable SSL certificate verification\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that we have imported our libraries and disabled the SSL certificates, now we can import our data. Here in this code we extracted our data directly from the UCI Machine Learning site. Since the data extracted was not ordered, we used the command .data.features to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 17, 'name': 'Breast Cancer Wisconsin (Diagnostic)', 'repository_url': 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic', 'data_url': 'https://archive.ics.uci.edu/static/public/17/data.csv', 'abstract': 'Diagnostic Wisconsin Breast Cancer Database.', 'area': 'Life Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 569, 'num_features': 30, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['Diagnosis'], 'index_col': ['ID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1993, 'last_updated': 'Mon Jul 17 2023', 'dataset_doi': '10.24432/C5DW2B', 'creators': ['William Wolberg', 'Olvi Mangasarian', 'Nick Street', 'W. Street'], 'intro_paper': {'title': 'Nuclear feature extraction for breast tumor diagnosis', 'authors': 'W. Street, W. Wolberg, O. Mangasarian', 'published_in': 'Electronic imaging', 'year': 1993, 'url': 'https://www.semanticscholar.org/paper/53f0fbb425bc14468eb3bf96b2e1d41ba8087f36', 'doi': '10.1117/12.148698'}, 'additional_info': {'summary': 'Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at http://www.cs.wisc.edu/~street/images/\\r\\n\\r\\nSeparating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\\r\\n\\r\\nThe actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\\r\\n\\r\\nThis database is also available through the UW CS ftp server:\\r\\nftp ftp.cs.wisc.edu\\r\\ncd math-prog/cpo-dataset/machine-learn/WDBC/', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1) ID number\\r\\n2) Diagnosis (M = malignant, B = benign)\\r\\n3-32)\\r\\n\\r\\nTen real-valued features are computed for each cell nucleus:\\r\\n\\r\\n\\ta) radius (mean of distances from center to points on the perimeter)\\r\\n\\tb) texture (standard deviation of gray-scale values)\\r\\n\\tc) perimeter\\r\\n\\td) area\\r\\n\\te) smoothness (local variation in radius lengths)\\r\\n\\tf) compactness (perimeter^2 / area - 1.0)\\r\\n\\tg) concavity (severity of concave portions of the contour)\\r\\n\\th) concave points (number of concave portions of the contour)\\r\\n\\ti) symmetry \\r\\n\\tj) fractal dimension (\"coastline approximation\" - 1)', 'citation': None}}\n",
      "                  name     role         type demographic description units  \\\n",
      "0                   ID       ID  Categorical        None        None  None   \n",
      "1            Diagnosis   Target  Categorical        None        None  None   \n",
      "2              radius1  Feature   Continuous        None        None  None   \n",
      "3             texture1  Feature   Continuous        None        None  None   \n",
      "4           perimeter1  Feature   Continuous        None        None  None   \n",
      "5                area1  Feature   Continuous        None        None  None   \n",
      "6          smoothness1  Feature   Continuous        None        None  None   \n",
      "7         compactness1  Feature   Continuous        None        None  None   \n",
      "8           concavity1  Feature   Continuous        None        None  None   \n",
      "9      concave_points1  Feature   Continuous        None        None  None   \n",
      "10           symmetry1  Feature   Continuous        None        None  None   \n",
      "11  fractal_dimension1  Feature   Continuous        None        None  None   \n",
      "12             radius2  Feature   Continuous        None        None  None   \n",
      "13            texture2  Feature   Continuous        None        None  None   \n",
      "14          perimeter2  Feature   Continuous        None        None  None   \n",
      "15               area2  Feature   Continuous        None        None  None   \n",
      "16         smoothness2  Feature   Continuous        None        None  None   \n",
      "17        compactness2  Feature   Continuous        None        None  None   \n",
      "18          concavity2  Feature   Continuous        None        None  None   \n",
      "19     concave_points2  Feature   Continuous        None        None  None   \n",
      "20           symmetry2  Feature   Continuous        None        None  None   \n",
      "21  fractal_dimension2  Feature   Continuous        None        None  None   \n",
      "22             radius3  Feature   Continuous        None        None  None   \n",
      "23            texture3  Feature   Continuous        None        None  None   \n",
      "24          perimeter3  Feature   Continuous        None        None  None   \n",
      "25               area3  Feature   Continuous        None        None  None   \n",
      "26         smoothness3  Feature   Continuous        None        None  None   \n",
      "27        compactness3  Feature   Continuous        None        None  None   \n",
      "28          concavity3  Feature   Continuous        None        None  None   \n",
      "29     concave_points3  Feature   Continuous        None        None  None   \n",
      "30           symmetry3  Feature   Continuous        None        None  None   \n",
      "31  fractal_dimension3  Feature   Continuous        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n",
      "15             no  \n",
      "16             no  \n",
      "17             no  \n",
      "18             no  \n",
      "19             no  \n",
      "20             no  \n",
      "21             no  \n",
      "22             no  \n",
      "23             no  \n",
      "24             no  \n",
      "25             no  \n",
      "26             no  \n",
      "27             no  \n",
      "28             no  \n",
      "29             no  \n",
      "30             no  \n",
      "31             no  \n"
     ]
    }
   ],
   "source": [
    "df = fetch_ucirepo(id=17) \n",
    "print(df.metadata) \n",
    "# variable information \n",
    "print(df.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'ids':            ID\n",
      "0      842302\n",
      "1      842517\n",
      "2    84300903\n",
      "3    84348301\n",
      "4    84358402\n",
      "..        ...\n",
      "564    926424\n",
      "565    926682\n",
      "566    926954\n",
      "567    927241\n",
      "568     92751\n",
      "\n",
      "[569 rows x 1 columns], 'features':      radius1  texture1  perimeter1   area1  smoothness1  compactness1  \\\n",
      "0      17.99     10.38      122.80  1001.0      0.11840       0.27760   \n",
      "1      20.57     17.77      132.90  1326.0      0.08474       0.07864   \n",
      "2      19.69     21.25      130.00  1203.0      0.10960       0.15990   \n",
      "3      11.42     20.38       77.58   386.1      0.14250       0.28390   \n",
      "4      20.29     14.34      135.10  1297.0      0.10030       0.13280   \n",
      "..       ...       ...         ...     ...          ...           ...   \n",
      "564    21.56     22.39      142.00  1479.0      0.11100       0.11590   \n",
      "565    20.13     28.25      131.20  1261.0      0.09780       0.10340   \n",
      "566    16.60     28.08      108.30   858.1      0.08455       0.10230   \n",
      "567    20.60     29.33      140.10  1265.0      0.11780       0.27700   \n",
      "568     7.76     24.54       47.92   181.0      0.05263       0.04362   \n",
      "\n",
      "     concavity1  concave_points1  symmetry1  fractal_dimension1  ...  radius3  \\\n",
      "0       0.30010          0.14710     0.2419             0.07871  ...   25.380   \n",
      "1       0.08690          0.07017     0.1812             0.05667  ...   24.990   \n",
      "2       0.19740          0.12790     0.2069             0.05999  ...   23.570   \n",
      "3       0.24140          0.10520     0.2597             0.09744  ...   14.910   \n",
      "4       0.19800          0.10430     0.1809             0.05883  ...   22.540   \n",
      "..          ...              ...        ...                 ...  ...      ...   \n",
      "564     0.24390          0.13890     0.1726             0.05623  ...   25.450   \n",
      "565     0.14400          0.09791     0.1752             0.05533  ...   23.690   \n",
      "566     0.09251          0.05302     0.1590             0.05648  ...   18.980   \n",
      "567     0.35140          0.15200     0.2397             0.07016  ...   25.740   \n",
      "568     0.00000          0.00000     0.1587             0.05884  ...    9.456   \n",
      "\n",
      "     texture3  perimeter3   area3  smoothness3  compactness3  concavity3  \\\n",
      "0       17.33      184.60  2019.0      0.16220       0.66560      0.7119   \n",
      "1       23.41      158.80  1956.0      0.12380       0.18660      0.2416   \n",
      "2       25.53      152.50  1709.0      0.14440       0.42450      0.4504   \n",
      "3       26.50       98.87   567.7      0.20980       0.86630      0.6869   \n",
      "4       16.67      152.20  1575.0      0.13740       0.20500      0.4000   \n",
      "..        ...         ...     ...          ...           ...         ...   \n",
      "564     26.40      166.10  2027.0      0.14100       0.21130      0.4107   \n",
      "565     38.25      155.00  1731.0      0.11660       0.19220      0.3215   \n",
      "566     34.12      126.70  1124.0      0.11390       0.30940      0.3403   \n",
      "567     39.42      184.60  1821.0      0.16500       0.86810      0.9387   \n",
      "568     30.37       59.16   268.6      0.08996       0.06444      0.0000   \n",
      "\n",
      "     concave_points3  symmetry3  fractal_dimension3  \n",
      "0             0.2654     0.4601             0.11890  \n",
      "1             0.1860     0.2750             0.08902  \n",
      "2             0.2430     0.3613             0.08758  \n",
      "3             0.2575     0.6638             0.17300  \n",
      "4             0.1625     0.2364             0.07678  \n",
      "..               ...        ...                 ...  \n",
      "564           0.2216     0.2060             0.07115  \n",
      "565           0.1628     0.2572             0.06637  \n",
      "566           0.1418     0.2218             0.07820  \n",
      "567           0.2650     0.4087             0.12400  \n",
      "568           0.0000     0.2871             0.07039  \n",
      "\n",
      "[569 rows x 30 columns], 'targets':     Diagnosis\n",
      "0           M\n",
      "1           M\n",
      "2           M\n",
      "3           M\n",
      "4           M\n",
      "..        ...\n",
      "564         M\n",
      "565         M\n",
      "566         M\n",
      "567         M\n",
      "568         B\n",
      "\n",
      "[569 rows x 1 columns], 'original':            ID  radius1  texture1  perimeter1   area1  smoothness1  \\\n",
      "0      842302    17.99     10.38      122.80  1001.0      0.11840   \n",
      "1      842517    20.57     17.77      132.90  1326.0      0.08474   \n",
      "2    84300903    19.69     21.25      130.00  1203.0      0.10960   \n",
      "3    84348301    11.42     20.38       77.58   386.1      0.14250   \n",
      "4    84358402    20.29     14.34      135.10  1297.0      0.10030   \n",
      "..        ...      ...       ...         ...     ...          ...   \n",
      "564    926424    21.56     22.39      142.00  1479.0      0.11100   \n",
      "565    926682    20.13     28.25      131.20  1261.0      0.09780   \n",
      "566    926954    16.60     28.08      108.30   858.1      0.08455   \n",
      "567    927241    20.60     29.33      140.10  1265.0      0.11780   \n",
      "568     92751     7.76     24.54       47.92   181.0      0.05263   \n",
      "\n",
      "     compactness1  concavity1  concave_points1  symmetry1  ...  texture3  \\\n",
      "0         0.27760     0.30010          0.14710     0.2419  ...     17.33   \n",
      "1         0.07864     0.08690          0.07017     0.1812  ...     23.41   \n",
      "2         0.15990     0.19740          0.12790     0.2069  ...     25.53   \n",
      "3         0.28390     0.24140          0.10520     0.2597  ...     26.50   \n",
      "4         0.13280     0.19800          0.10430     0.1809  ...     16.67   \n",
      "..            ...         ...              ...        ...  ...       ...   \n",
      "564       0.11590     0.24390          0.13890     0.1726  ...     26.40   \n",
      "565       0.10340     0.14400          0.09791     0.1752  ...     38.25   \n",
      "566       0.10230     0.09251          0.05302     0.1590  ...     34.12   \n",
      "567       0.27700     0.35140          0.15200     0.2397  ...     39.42   \n",
      "568       0.04362     0.00000          0.00000     0.1587  ...     30.37   \n",
      "\n",
      "     perimeter3   area3  smoothness3  compactness3  concavity3  \\\n",
      "0        184.60  2019.0      0.16220       0.66560      0.7119   \n",
      "1        158.80  1956.0      0.12380       0.18660      0.2416   \n",
      "2        152.50  1709.0      0.14440       0.42450      0.4504   \n",
      "3         98.87   567.7      0.20980       0.86630      0.6869   \n",
      "4        152.20  1575.0      0.13740       0.20500      0.4000   \n",
      "..          ...     ...          ...           ...         ...   \n",
      "564      166.10  2027.0      0.14100       0.21130      0.4107   \n",
      "565      155.00  1731.0      0.11660       0.19220      0.3215   \n",
      "566      126.70  1124.0      0.11390       0.30940      0.3403   \n",
      "567      184.60  1821.0      0.16500       0.86810      0.9387   \n",
      "568       59.16   268.6      0.08996       0.06444      0.0000   \n",
      "\n",
      "     concave_points3  symmetry3  fractal_dimension3  Diagnosis  \n",
      "0             0.2654     0.4601             0.11890          M  \n",
      "1             0.1860     0.2750             0.08902          M  \n",
      "2             0.2430     0.3613             0.08758          M  \n",
      "3             0.2575     0.6638             0.17300          M  \n",
      "4             0.1625     0.2364             0.07678          M  \n",
      "..               ...        ...                 ...        ...  \n",
      "564           0.2216     0.2060             0.07115          M  \n",
      "565           0.1628     0.2572             0.06637          M  \n",
      "566           0.1418     0.2218             0.07820          M  \n",
      "567           0.2650     0.4087             0.12400          M  \n",
      "568           0.0000     0.2871             0.07039          B  \n",
      "\n",
      "[569 rows x 32 columns], 'headers': Index(['ID', 'radius1', 'texture1', 'perimeter1', 'area1', 'smoothness1',\n",
      "       'compactness1', 'concavity1', 'concave_points1', 'symmetry1',\n",
      "       'fractal_dimension1', 'radius2', 'texture2', 'perimeter2', 'area2',\n",
      "       'smoothness2', 'compactness2', 'concavity2', 'concave_points2',\n",
      "       'symmetry2', 'fractal_dimension2', 'radius3', 'texture3', 'perimeter3',\n",
      "       'area3', 'smoothness3', 'compactness3', 'concavity3', 'concave_points3',\n",
      "       'symmetry3', 'fractal_dimension3', 'Diagnosis'],\n",
      "      dtype='object')}, 'metadata': {'uci_id': 17, 'name': 'Breast Cancer Wisconsin (Diagnostic)', 'repository_url': 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic', 'data_url': 'https://archive.ics.uci.edu/static/public/17/data.csv', 'abstract': 'Diagnostic Wisconsin Breast Cancer Database.', 'area': 'Life Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 569, 'num_features': 30, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['Diagnosis'], 'index_col': ['ID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1993, 'last_updated': 'Mon Jul 17 2023', 'dataset_doi': '10.24432/C5DW2B', 'creators': ['William Wolberg', 'Olvi Mangasarian', 'Nick Street', 'W. Street'], 'intro_paper': {'title': 'Nuclear feature extraction for breast tumor diagnosis', 'authors': 'W. Street, W. Wolberg, O. Mangasarian', 'published_in': 'Electronic imaging', 'year': 1993, 'url': 'https://www.semanticscholar.org/paper/53f0fbb425bc14468eb3bf96b2e1d41ba8087f36', 'doi': '10.1117/12.148698'}, 'additional_info': {'summary': 'Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at http://www.cs.wisc.edu/~street/images/\\r\\n\\r\\nSeparating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\\r\\n\\r\\nThe actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\\r\\n\\r\\nThis database is also available through the UW CS ftp server:\\r\\nftp ftp.cs.wisc.edu\\r\\ncd math-prog/cpo-dataset/machine-learn/WDBC/', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1) ID number\\r\\n2) Diagnosis (M = malignant, B = benign)\\r\\n3-32)\\r\\n\\r\\nTen real-valued features are computed for each cell nucleus:\\r\\n\\r\\n\\ta) radius (mean of distances from center to points on the perimeter)\\r\\n\\tb) texture (standard deviation of gray-scale values)\\r\\n\\tc) perimeter\\r\\n\\td) area\\r\\n\\te) smoothness (local variation in radius lengths)\\r\\n\\tf) compactness (perimeter^2 / area - 1.0)\\r\\n\\tg) concavity (severity of concave portions of the contour)\\r\\n\\th) concave points (number of concave portions of the contour)\\r\\n\\ti) symmetry \\r\\n\\tj) fractal dimension (\"coastline approximation\" - 1)', 'citation': None}}, 'variables':                   name     role         type demographic description units  \\\n",
      "0                   ID       ID  Categorical        None        None  None   \n",
      "1            Diagnosis   Target  Categorical        None        None  None   \n",
      "2              radius1  Feature   Continuous        None        None  None   \n",
      "3             texture1  Feature   Continuous        None        None  None   \n",
      "4           perimeter1  Feature   Continuous        None        None  None   \n",
      "5                area1  Feature   Continuous        None        None  None   \n",
      "6          smoothness1  Feature   Continuous        None        None  None   \n",
      "7         compactness1  Feature   Continuous        None        None  None   \n",
      "8           concavity1  Feature   Continuous        None        None  None   \n",
      "9      concave_points1  Feature   Continuous        None        None  None   \n",
      "10           symmetry1  Feature   Continuous        None        None  None   \n",
      "11  fractal_dimension1  Feature   Continuous        None        None  None   \n",
      "12             radius2  Feature   Continuous        None        None  None   \n",
      "13            texture2  Feature   Continuous        None        None  None   \n",
      "14          perimeter2  Feature   Continuous        None        None  None   \n",
      "15               area2  Feature   Continuous        None        None  None   \n",
      "16         smoothness2  Feature   Continuous        None        None  None   \n",
      "17        compactness2  Feature   Continuous        None        None  None   \n",
      "18          concavity2  Feature   Continuous        None        None  None   \n",
      "19     concave_points2  Feature   Continuous        None        None  None   \n",
      "20           symmetry2  Feature   Continuous        None        None  None   \n",
      "21  fractal_dimension2  Feature   Continuous        None        None  None   \n",
      "22             radius3  Feature   Continuous        None        None  None   \n",
      "23            texture3  Feature   Continuous        None        None  None   \n",
      "24          perimeter3  Feature   Continuous        None        None  None   \n",
      "25               area3  Feature   Continuous        None        None  None   \n",
      "26         smoothness3  Feature   Continuous        None        None  None   \n",
      "27        compactness3  Feature   Continuous        None        None  None   \n",
      "28          concavity3  Feature   Continuous        None        None  None   \n",
      "29     concave_points3  Feature   Continuous        None        None  None   \n",
      "30           symmetry3  Feature   Continuous        None        None  None   \n",
      "31  fractal_dimension3  Feature   Continuous        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n",
      "15             no  \n",
      "16             no  \n",
      "17             no  \n",
      "18             no  \n",
      "19             no  \n",
      "20             no  \n",
      "21             no  \n",
      "22             no  \n",
      "23             no  \n",
      "24             no  \n",
      "25             no  \n",
      "26             no  \n",
      "27             no  \n",
      "28             no  \n",
      "29             no  \n",
      "30             no  \n",
      "31             no  }\n"
     ]
    }
   ],
   "source": [
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the outcomes using the two codes: \n",
    "So the code above this, shows all the features and the type of vraiables, however the problem I keep getting is the the diagnosis does not show up with the rest of the data. I personally would like to have the diagnosis in the same data.  So for now we will probably download the data, but we did successfully extract the data from the uciml website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>symmetry1</th>\n",
       "      <th>fractal_dimension1</th>\n",
       "      <th>...</th>\n",
       "      <th>radius3</th>\n",
       "      <th>texture3</th>\n",
       "      <th>perimeter3</th>\n",
       "      <th>area3</th>\n",
       "      <th>smoothness3</th>\n",
       "      <th>compactness3</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius1  texture1  perimeter1   area1  smoothness1  compactness1  \\\n",
       "0    17.99     10.38      122.80  1001.0      0.11840       0.27760   \n",
       "1    20.57     17.77      132.90  1326.0      0.08474       0.07864   \n",
       "2    19.69     21.25      130.00  1203.0      0.10960       0.15990   \n",
       "3    11.42     20.38       77.58   386.1      0.14250       0.28390   \n",
       "4    20.29     14.34      135.10  1297.0      0.10030       0.13280   \n",
       "\n",
       "   concavity1  concave_points1  symmetry1  fractal_dimension1  ...  radius3  \\\n",
       "0      0.3001          0.14710     0.2419             0.07871  ...    25.38   \n",
       "1      0.0869          0.07017     0.1812             0.05667  ...    24.99   \n",
       "2      0.1974          0.12790     0.2069             0.05999  ...    23.57   \n",
       "3      0.2414          0.10520     0.2597             0.09744  ...    14.91   \n",
       "4      0.1980          0.10430     0.1809             0.05883  ...    22.54   \n",
       "\n",
       "   texture3  perimeter3   area3  smoothness3  compactness3  concavity3  \\\n",
       "0     17.33      184.60  2019.0       0.1622        0.6656      0.7119   \n",
       "1     23.41      158.80  1956.0       0.1238        0.1866      0.2416   \n",
       "2     25.53      152.50  1709.0       0.1444        0.4245      0.4504   \n",
       "3     26.50       98.87   567.7       0.2098        0.8663      0.6869   \n",
       "4     16.67      152.20  1575.0       0.1374        0.2050      0.4000   \n",
       "\n",
       "   concave_points3  symmetry3  fractal_dimension3  \n",
       "0           0.2654     0.4601             0.11890  \n",
       "1           0.1860     0.2750             0.08902  \n",
       "2           0.2430     0.3613             0.08758  \n",
       "3           0.2575     0.6638             0.17300  \n",
       "4           0.1625     0.2364             0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer = fetch_ucirepo(id=17) \n",
    "Features = breast_cancer.data.features\n",
    "Features.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would also like to get a general summary of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   radius1             569 non-null    float64\n",
      " 1   texture1            569 non-null    float64\n",
      " 2   perimeter1          569 non-null    float64\n",
      " 3   area1               569 non-null    float64\n",
      " 4   smoothness1         569 non-null    float64\n",
      " 5   compactness1        569 non-null    float64\n",
      " 6   concavity1          569 non-null    float64\n",
      " 7   concave_points1     569 non-null    float64\n",
      " 8   symmetry1           569 non-null    float64\n",
      " 9   fractal_dimension1  569 non-null    float64\n",
      " 10  radius2             569 non-null    float64\n",
      " 11  texture2            569 non-null    float64\n",
      " 12  perimeter2          569 non-null    float64\n",
      " 13  area2               569 non-null    float64\n",
      " 14  smoothness2         569 non-null    float64\n",
      " 15  compactness2        569 non-null    float64\n",
      " 16  concavity2          569 non-null    float64\n",
      " 17  concave_points2     569 non-null    float64\n",
      " 18  symmetry2           569 non-null    float64\n",
      " 19  fractal_dimension2  569 non-null    float64\n",
      " 20  radius3             569 non-null    float64\n",
      " 21  texture3            569 non-null    float64\n",
      " 22  perimeter3          569 non-null    float64\n",
      " 23  area3               569 non-null    float64\n",
      " 24  smoothness3         569 non-null    float64\n",
      " 25  compactness3        569 non-null    float64\n",
      " 26  concavity3          569 non-null    float64\n",
      " 27  concave_points3     569 non-null    float64\n",
      " 28  symmetry3           569 non-null    float64\n",
      " 29  fractal_dimension3  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "Features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>symmetry1</th>\n",
       "      <th>fractal_dimension1</th>\n",
       "      <th>...</th>\n",
       "      <th>radius3</th>\n",
       "      <th>texture3</th>\n",
       "      <th>perimeter3</th>\n",
       "      <th>area3</th>\n",
       "      <th>smoothness3</th>\n",
       "      <th>compactness3</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          radius1    texture1  perimeter1        area1  smoothness1  \\\n",
       "count  569.000000  569.000000  569.000000   569.000000   569.000000   \n",
       "mean    14.127292   19.289649   91.969033   654.889104     0.096360   \n",
       "std      3.524049    4.301036   24.298981   351.914129     0.014064   \n",
       "min      6.981000    9.710000   43.790000   143.500000     0.052630   \n",
       "25%     11.700000   16.170000   75.170000   420.300000     0.086370   \n",
       "50%     13.370000   18.840000   86.240000   551.100000     0.095870   \n",
       "75%     15.780000   21.800000  104.100000   782.700000     0.105300   \n",
       "max     28.110000   39.280000  188.500000  2501.000000     0.163400   \n",
       "\n",
       "       compactness1  concavity1  concave_points1   symmetry1  \\\n",
       "count    569.000000  569.000000       569.000000  569.000000   \n",
       "mean       0.104341    0.088799         0.048919    0.181162   \n",
       "std        0.052813    0.079720         0.038803    0.027414   \n",
       "min        0.019380    0.000000         0.000000    0.106000   \n",
       "25%        0.064920    0.029560         0.020310    0.161900   \n",
       "50%        0.092630    0.061540         0.033500    0.179200   \n",
       "75%        0.130400    0.130700         0.074000    0.195700   \n",
       "max        0.345400    0.426800         0.201200    0.304000   \n",
       "\n",
       "       fractal_dimension1  ...     radius3    texture3  perimeter3  \\\n",
       "count          569.000000  ...  569.000000  569.000000  569.000000   \n",
       "mean             0.062798  ...   16.269190   25.677223  107.261213   \n",
       "std              0.007060  ...    4.833242    6.146258   33.602542   \n",
       "min              0.049960  ...    7.930000   12.020000   50.410000   \n",
       "25%              0.057700  ...   13.010000   21.080000   84.110000   \n",
       "50%              0.061540  ...   14.970000   25.410000   97.660000   \n",
       "75%              0.066120  ...   18.790000   29.720000  125.400000   \n",
       "max              0.097440  ...   36.040000   49.540000  251.200000   \n",
       "\n",
       "             area3  smoothness3  compactness3  concavity3  concave_points3  \\\n",
       "count   569.000000   569.000000    569.000000  569.000000       569.000000   \n",
       "mean    880.583128     0.132369      0.254265    0.272188         0.114606   \n",
       "std     569.356993     0.022832      0.157336    0.208624         0.065732   \n",
       "min     185.200000     0.071170      0.027290    0.000000         0.000000   \n",
       "25%     515.300000     0.116600      0.147200    0.114500         0.064930   \n",
       "50%     686.500000     0.131300      0.211900    0.226700         0.099930   \n",
       "75%    1084.000000     0.146000      0.339100    0.382900         0.161400   \n",
       "max    4254.000000     0.222600      1.058000    1.252000         0.291000   \n",
       "\n",
       "        symmetry3  fractal_dimension3  \n",
       "count  569.000000          569.000000  \n",
       "mean     0.290076            0.083946  \n",
       "std      0.061867            0.018061  \n",
       "min      0.156500            0.055040  \n",
       "25%      0.250400            0.071460  \n",
       "50%      0.282200            0.080040  \n",
       "75%      0.317900            0.092080  \n",
       "max      0.663800            0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0      842302         M        17.99         10.38          122.80     1001.0   \n",
      "1      842517         M        20.57         17.77          132.90     1326.0   \n",
      "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3    84348301         M        11.42         20.38           77.58      386.1   \n",
      "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
      "..        ...       ...          ...           ...             ...        ...   \n",
      "564    926424         M        21.56         22.39          142.00     1479.0   \n",
      "565    926682         M        20.13         28.25          131.20     1261.0   \n",
      "566    926954         M        16.60         28.08          108.30      858.1   \n",
      "567    927241         M        20.60         29.33          140.10     1265.0   \n",
      "568     92751         B         7.76         24.54           47.92      181.0   \n",
      "\n",
      "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0            0.11840           0.27760         0.30010              0.14710   \n",
      "1            0.08474           0.07864         0.08690              0.07017   \n",
      "2            0.10960           0.15990         0.19740              0.12790   \n",
      "3            0.14250           0.28390         0.24140              0.10520   \n",
      "4            0.10030           0.13280         0.19800              0.10430   \n",
      "..               ...               ...             ...                  ...   \n",
      "564          0.11100           0.11590         0.24390              0.13890   \n",
      "565          0.09780           0.10340         0.14400              0.09791   \n",
      "566          0.08455           0.10230         0.09251              0.05302   \n",
      "567          0.11780           0.27700         0.35140              0.15200   \n",
      "568          0.05263           0.04362         0.00000              0.00000   \n",
      "\n",
      "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "0    ...          17.33           184.60      2019.0           0.16220   \n",
      "1    ...          23.41           158.80      1956.0           0.12380   \n",
      "2    ...          25.53           152.50      1709.0           0.14440   \n",
      "3    ...          26.50            98.87       567.7           0.20980   \n",
      "4    ...          16.67           152.20      1575.0           0.13740   \n",
      "..   ...            ...              ...         ...               ...   \n",
      "564  ...          26.40           166.10      2027.0           0.14100   \n",
      "565  ...          38.25           155.00      1731.0           0.11660   \n",
      "566  ...          34.12           126.70      1124.0           0.11390   \n",
      "567  ...          39.42           184.60      1821.0           0.16500   \n",
      "568  ...          30.37            59.16       268.6           0.08996   \n",
      "\n",
      "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "0              0.66560           0.7119                0.2654          0.4601   \n",
      "1              0.18660           0.2416                0.1860          0.2750   \n",
      "2              0.42450           0.4504                0.2430          0.3613   \n",
      "3              0.86630           0.6869                0.2575          0.6638   \n",
      "4              0.20500           0.4000                0.1625          0.2364   \n",
      "..                 ...              ...                   ...             ...   \n",
      "564            0.21130           0.4107                0.2216          0.2060   \n",
      "565            0.19220           0.3215                0.1628          0.2572   \n",
      "566            0.30940           0.3403                0.1418          0.2218   \n",
      "567            0.86810           0.9387                0.2650          0.4087   \n",
      "568            0.06444           0.0000                0.0000          0.2871   \n",
      "\n",
      "     fractal_dimension_worst  Unnamed: 32  \n",
      "0                    0.11890          NaN  \n",
      "1                    0.08902          NaN  \n",
      "2                    0.08758          NaN  \n",
      "3                    0.17300          NaN  \n",
      "4                    0.07678          NaN  \n",
      "..                       ...          ...  \n",
      "564                  0.07115          NaN  \n",
      "565                  0.06637          NaN  \n",
      "566                  0.07820          NaN  \n",
      "567                  0.12400          NaN  \n",
      "568                  0.07039          NaN  \n",
      "\n",
      "[569 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "### IMPORTING THE DATA USING A CSV FILE: \n",
    "data = pd.read_csv(\"/Users/kashishbhatt/Downloads/data.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Diagnosis: diagnosis\n",
      "B    357\n",
      "M    212\n",
      "Name: count, dtype: int64 \n",
      " _____________________\n",
      "Percentage of Diagnosis: diagnosis\n",
      "B    62.741652\n",
      "M    37.258348\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## here I will obtain the number of diagnosis and the percentage of them: \n",
    "print(\"Number of Diagnosis:\", data[\"diagnosis\"].value_counts(), \"\\n\", \"_____________________\")\n",
    "print(\"Percentage of Diagnosis:\", data[\"diagnosis\"].value_counts() * 100 / len(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression:\n",
    "\n",
    "Logistic regression is a Machine learning Technique, it is classified under supervised machine learning technique. Now one might ask, what is supervised technique? Well in machine learning there are two types of learning: supervised and un-supervised. Supervised machine learning is also known as classification data because it utilizes the use of labels in input and output data, while unsupervised learning doesn't but often is utilized to understand the relationships between inside the dataset. \n",
    "\n",
    "Logistic regression was first used in biological dataset in the 20th century and since then it has been widely used for social media based studies as well, as stated in the research paper used in this article. Its is best to use logistic regression when there is a binary classification. Meaning that there are only two outcomes like pass/fail, yes/no, diagnosed/not diagnosed, etc. The goal of logistic regression is to do predictive analysis, or in better terms estimate the probabilities of an event occurring. The outcome in this type of model is often coded as 0, which is the negative outcome, and 1, which is the positive outcome. So the dependent variable, that we are testing is bounded between 0 and 1. So that means that the predictive values should always fall within the range of 0 to 100%. The sigmoid function in the logistic regression assigns that probability. \n",
    "\n",
    "Mathematically, logistic regression calculates the probability or odd by this formula: \n",
    "\n",
    "$p = \\frac{1}{1 + e^{-(b_0 + b_1)}}$\n",
    "\n",
    "Logistic regression also has two phases, one is the forward propagation and backward propagation. So what are they? Forward propagation is when we multiply weights with features and since weights are often unknown we can assign random values to them. We finally then do a prediction based on threshold values, and once the prediction is done, the value of the prediction is then compared to the value of the values that were observed. and using that a loss function is generated. The loss function is what indicates how far the predicted value is from the real/observed value. backward propagation then comes in, whose goal is to update the weights according to the cost function. \n",
    "\n",
    "Here is the loss function: \n",
    "\n",
    "$Loss(y, \\hat{y}) = -[y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y})]$\n",
    "\n",
    "Here is the cost function: \n",
    "\n",
    "$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m}[y^{(i)} \\cdot \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\cdot \\log(1 - \\hat{y}^{(i)})]$\n",
    "\n",
    "The sigmoid function: \n",
    "\n",
    "$\\sigma(x) = \\frac{1}{1 + e^{-x}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE FOR LOGISTIC REGRESSION: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries: \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956140350877193\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.95      0.99      0.97        71\n",
      "           M       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Confusion Matrix:\n",
      "[[70  1]\n",
      " [ 4 39]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = breast_cancer_wisconsin_diagnostic.data.features \n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets \n",
    "\n",
    "# so we have our data here according to machine learning techniques. \n",
    "\n",
    "# now we want to split the data: \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# now we want to create a model and train it: \n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#And finally we want to predict the data's outcomes \n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# And now we want to evaluate the model. The model evaluation usually means that we are using common metrics to include the accuracy, precision, recall, F1-score and the confusion matrix.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report:\\n{report}')\n",
    "print(f'Confusion Matrix:\\n{confusion}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the above details: \n",
    "\n",
    "Accuracy: 0.956140350877193\n",
    "\n",
    "Classification Report:\n",
    "|           | precision |   recall |   f1-score |   support |\n",
    "|:----------|----------:|---------:|-----------:|----------:|\n",
    "| B         |     0.95  |     0.99  |       0.97 |       71  |\n",
    "| M         |     0.97  |     0.91  |       0.94 |       43  |\n",
    "|           |           |          |            |           |\n",
    "| accuracy  |     0.96  |     0.956 |       0.96 |      114  |\n",
    "| macro avg |     0.96  |     0.95  |       0.95 |      114  |\n",
    "| weighted avg |     0.96  |     0.96  |       0.96 |      114  |\n",
    "\n",
    "Confusion Matrix:\n",
    "|          |   |   |\n",
    "|----------|--|--|\n",
    "|    B      | 70 |  1 |\n",
    "|    M     |  4 | 39 |\n",
    "\n",
    "\n",
    "So this is a classification report with a confusion matrix. These provide us with the information regarding the logistic model for binary classification. In this report. the precision (which is the accuracy of positive predictions) shows 0.95 or 95% for begin and 0.97 or 97% for Malignant, the classification is B and M respectively. The recall is the true positive rate and its is the model's ability to identify all relevant instances. And here there is 0.99 or 99% positive recall for benign, meaning that 99% were accurately identified and for Malignant it was 0.91, or 91% were accurately identified. The F1 score is the mean of precision and recall, and its 0.97 for benign and 0.94 for Malignant. The support is the number of samples in each class. The over all accuracy of the model is 0.96 or 96% and 0.956 and 0.96 for benign and malignant respectively. Macro avg is the average of each column. \n",
    "\n",
    "\n",
    "The confusion matrix shows us the number of instances that were classified correctly and incorrectly. For Benign it was 70 samples that were correctly identified and 1 was incorrectly identified. For Malignant there were 39 samples that were correctly classified and 4 were incorrect. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), ['radius_mean', 'concavity_mean'])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/index.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), ['radius_mean', 'concavity_mean'])' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kashishbhatt/Desktop/Codes /cancer_analysis/cancer-1.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kashishbhatt/Desktop/Codes%20/cancer_analysis/cancer-1.ipynb#X51sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m feature2 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mconcavity_mean\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kashishbhatt/Desktop/Codes%20/cancer_analysis/cancer-1.ipynb#X51sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# we will then extract the two selected features from the data \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kashishbhatt/Desktop/Codes%20/cancer_analysis/cancer-1.ipynb#X51sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m X_train_selected \u001b[39m=\u001b[39m X_train[:, [feature1, feature2]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kashishbhatt/Desktop/Codes%20/cancer_analysis/cancer-1.ipynb#X51sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m X_test_selected \u001b[39m=\u001b[39m X_test[:, [feature1, feature2]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kashishbhatt/Desktop/Codes%20/cancer_analysis/cancer-1.ipynb#X51sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# now we will try to fit the logistic regression on the selected features \u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3660\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3660\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[1;32m   3661\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:5737\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5733\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m   5734\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5735\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5736\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5737\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), ['radius_mean', 'concavity_mean'])"
     ]
    }
   ],
   "source": [
    "## CREATING A LOGISTIC MODEL DIAGRAM ACCORDING TO THE RESEARCH PAPER: \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# here we will selected the two features we want to visualize: \n",
    "\n",
    "feature1 = \"radius_mean\"\n",
    "feature2 = \"concavity_mean\"\n",
    "\n",
    "# we will then extract the two selected features from the data \n",
    "X_train_selected = X_train[:, [feature1, feature2]]\n",
    "X_test_selected = X_test[:, [feature1, feature2]]\n",
    "\n",
    "\n",
    "# now we will try to fit the logistic regression on the selected features \n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Now we will create a mesh grid to plot the decision boundary\n",
    "\n",
    "x_min, x_max = X_train_selected[:, 0].min() - 1, X_train_selected[:, 0].max() + 1\n",
    "y_min, y_max = X_train_selected[:, 1].min() - 1, X_train_selected[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary and data points\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "plt.scatter(X_train_selected[:, 0], X_train_selected[:, 1], c=y_train, marker='o')\n",
    "plt.xlabel(f'Feature {feature1}')\n",
    "plt.ylabel(f'Feature {feature2}')\n",
    "plt.title('Logistic Regression Decision Boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['radius_mean', 'concavity_mean'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/kashishbhatt/Desktop/Codes /cancer_analysis/cancer-1.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kashishbhatt/Desktop/Codes%20/cancer_analysis/cancer-1.ipynb#X52sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m feature2 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mconcavity_mean\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kashishbhatt/Desktop/Codes%20/cancer_analysis/cancer-1.ipynb#X52sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Extract the two selected features from the data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kashishbhatt/Desktop/Codes%20/cancer_analysis/cancer-1.ipynb#X52sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m X_train_selected \u001b[39m=\u001b[39m X_train[[feature1, feature2]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kashishbhatt/Desktop/Codes%20/cancer_analysis/cancer-1.ipynb#X52sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m X_test_selected \u001b[39m=\u001b[39m X_test[[feature1, feature2]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kashishbhatt/Desktop/Codes%20/cancer_analysis/cancer-1.ipynb#X52sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Fit the logistic regression on the selected features\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5936\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5937\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 5938\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   5941\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['radius_mean', 'concavity_mean'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the selected features\n",
    "feature1 = \"radius_mean\"\n",
    "feature2 = \"concavity_mean\"\n",
    "\n",
    "# Extract the two selected features from the data\n",
    "X_train_selected = X_train[[feature1, feature2]]\n",
    "X_test_selected = X_test[[feature1, feature2]]\n",
    "\n",
    "# Fit the logistic regression on the selected features\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Create a mesh grid to plot the decision boundary\n",
    "x_min, x_max = X_train_selected[feature1].min() - 1, X_train_selected[feature1].max() + 1\n",
    "y_min, y_max = X_train_selected[feature2].min() - 1, X_train_selected[feature2].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary and data points\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "plt.scatter(X_train_selected[feature1], X_train_selected[feature2], c=y_train, marker='o')\n",
    "plt.xlabel(f'Feature: {feature1}')\n",
    "plt.ylabel(f'Feature: {feature2}')\n",
    "plt.title('Logistic Regression Decision Boundary')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor (KNN): \n",
    "\n",
    "K-Nearest Neighbor, also known as KNN, is a supervised ML techniques that uses proximity to make classifications. It is great to use in solving classification and regression problems. In this, the algorithms the data points that are the most similar to each other are often the closer to each other. In KNN, K is the numerical value for the K-nearest Neighbor. Its is one of those ML algorithms that don't have a training phase. The predictions in this model are made based on euclidean distance to the K-nearest neighbors. In the paper this algorithm was already applied to the the cancer dataset, using the labels malignant and benign. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)\n",
    "\n",
    "Support Vector Machine (SVM) is one of the most popular ML techniques. This algorithm can be best used on small but complex datasets. Like logistic regression, the objective of SVM is to find the best hyperplane, however in SVM the goal is to use statistical approach instead of probabilistic approach. The N-dimension that classifies the data points in the hyper-plane diversifies based on the number of features. To get the best predictions you want to maximize the number of features. The downside to SVM is that there is a small trade off between large margin and the training data. Where the margin is the distance between hyper-plane and the nearest data points from each class. \n",
    "\n",
    "Here is the equation of the linear SVM: \n",
    "$y(x) = \\text{sign}(\\mathbf{w} \\cdot \\mathbf{x} + b)$\n",
    "\n",
    "Where: \n",
    "y(x) = classification label for input vector\n",
    "W = is the weight vector \n",
    "dot (.) = is the dot product\n",
    "b = bias term \n",
    "sign(.) = is the sign function that returns: \n",
    "    +1 = positive value\n",
    "    0 = neutral \n",
    "    -1 = negative value \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
